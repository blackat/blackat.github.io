---
layout: single
title: "Kafka 101"
date: '2019-03-06'
last_modified_at: '2019-03-06'
comments: true
categories:
  - kafka, java
tags:
  - [kafka, java]
toc: true
toc_label: "On this page"
toc_icon: "list"
toc_sticky: true
---

# Install and start Kafka and Zookeeper

To have launchd start kafka now and restart at login:
  brew services start kafka
Or, if you don't want/need a background service you can just run:
  zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties & kafka-server-start /usr/local/etc/kafka/server.properties

## Features

Kafka provides fault-tolerance and resilience.
A Kafka cluster includes more than one broker (server).

## Grammar

- topic
- broker
- cluster
- partition
- replica
- leader
- in-sync replica
- log

Producer: Sends message to Kafka
Consumer: Retrieves messages from Kafka
Topics: Logical name of where message are stored in the broker
ZooKeeper ensemble: Helps maintain consensus in the cluster
Broker: Handles the commit log
Log: it is append only, each one is made up of entries labelled with offset numbers

## Create a Kafka cluster

kafka-server-start /usr/local/etc/kafka/server0.properties
kafka-server-start /usr/local/etc/kafka/server1.properties
kafka-server-start /usr/local/etc/kafka/server2.properties

  jps command to see the processes for kafka and zookeeper

## Create a Topic

Each message consists of a Key and a Value.
kafka-topics --zookeeper localhost:2181 --create --topic helloworld --partitions 3 --replication-factor 3
kafka-topics --zookeeper localhost:2181 --list

Once the topic has been created we can start to send messages.
Topic can be auto-create, this feature can be disabled and create topic manually to have better control.

### Topic

Topics are actually made out of units called partitions. In other words, one or many partitions can make up a single topic.
A single partition only exists on one broker and will not be split between brokers.
The partition is even further broken up into segment files (the actual) files written on the disk drive.

If you have a topic made up of 3 partitions and a replication factor of 3, each and every partitions will have a leader elected. The others 2 (in this case) will be followers that update their information from their partition leader.
Producers and consumers will only read or write (in happy path scenarios) from the leader of each partition it is assigned.

### View Topic Layout

kafka-topics --describe --zookeeper localhost:2181 --topic helloworld

## Producer/Cosnumer command

run a produce
kafka-console-producer --broker-list localhost:9092 --topic helloworld
kafka-console-consumer --bootstrap-server localhost:9092 --topic helloworld --from-beginning

## Zookeeper

Distributed store which is used to provide configuration and synchronization services in a high available way.
To act as one correct application, these brokers need to not only communicate with each other, they also need to reach agreement.
Agreeing on who the leader of a partition is, is one example of the practical application of ZooKeeper within the Kafka ecosystem.

## Kafka Architecture

One of the keys for Kafka is its usage of the pagecache of the operating system. By avoiding caching in the JVM heap, the brokers can help avoid some of the issues that large heaps can hold, ie. long or frequent garbage collection pauses.

Another design consideration was the access pattern of data. While new messages flood in, it is likely that the latest messages would be of most interest to many consumers which could then be served from this cache.

Kafka ecosystem works as a distributed system, producers send data to it.

### commit log

What makes the commit log special is its append only nature in which events are added to the end.
In most traditional systems, linear read and writes usually perform better than random operations that would require spinning disks.
Reading a message does not remove it from the system or exclude it from other consumers.

### Streaming process

Data does not end. The code processing data has to process them _all the time_ and not waiting for a request or a time frame to run. The consumer, for instance, has an infinite loop to process the constant flow of data that does not have an end. Data sometimes is huge, sometimes not but constantly flowing between destinations.

Data streaming journey.

## Designing Architecture

### Kafka Connect

